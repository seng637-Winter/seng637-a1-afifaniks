> **SENG 637 - Dependability and Reliability of Software Systems**

**Lab. Report \#1 – Introduction to Testing and Defect Tracking**

| Group: 16          |
|-------------------------------|
| Sayan                    |   
| Md Afif Al              |   
| Sutirtha                  |   
| Abhijit             |
| Moshfiq-Us-Saleheen |

[//]: # (**Table of Contents**)

[//]: # ()

[//]: # (&#40;When you finish writing, update the following list using right click, then)

[//]: # (“Update Field”&#41;)

[//]: # ([1 Introduction	1]&#40;#_Toc439194677&#41;)

[//]: # ()

[//]: # ([2 High-level description of the exploratory testing plan	1]&#40;#_Toc439194678&#41;)

[//]: # ()

[//]: # ([3 Comparison of exploratory and manual functional testing	1]&#40;#_Toc439194679&#41;)

[//]: # ()

[//]: # ([4 Notes and discussion of the peer reviews of defect reports	1]&#40;#_Toc439194680&#41;)

[//]: # ()

[//]: # ([5 How the pair testing was managed and team work/effort was)

[//]: # (divided	1]&#40;#_Toc439194681&#41;)

[//]: # ()

[//]: # ([6 Difficulties encountered, challenges overcome, and lessons)

[//]: # (learned	1]&#40;#_Toc439194682&#41;)

# Table of Contents

1. [Introduction](#introduction)
2. [High-level description of the exploratory testing plan](#high-level-description-of-the-exploratory-testing-plan)
3. [Comparison of exploratory and manual functional testing](#comparison-of-exploratory-and-manual-functional-testing)
4. [Notes and discussion of the peer reviews of defect reports](#notes-and-discussion-of-the-peer-reviews-of-defect-reports)
5. [How the pair testing was managed and team work/effort was divided](#how-the-pair-testing-was-managed-and-team-workeffort-was-divided)
6. [Challenges Encountered, Solutions Implemented and Knowledge Acquired](#challenges-encountered-solutions-implemented-and-knowledge-acquired)
7. [Feedback of the Assignment](#feedback-of-the-assignment)

# Introduction

For this assignment, we applied exploratory testing and manual scripted tests to discover several existing bugs on the given **ATM System** with 2 different versions (1.0, 1.1). In our testing, we were able to identify several critical bugs and listed the bugs in a JIRA backlog. This lab introduced us with different approaches that we could follow to find bugs in software systems and introduced us with industry standard tools like JIRA. We used this opportunity to broaden our knowledge software testing which may help us with our career in the software industry.

The JIRA backlog that we used for this project can be accessed by the given URL: https://afifaniks.atlassian.net/jira/software/projects/SENG637/boards/2/backlog

We exported the JIRA backlog in different format for review. The exports are hyperlinked below and also available in the`deliverables` directory.

 - **JIRA Backlog Spreadsheet: [Backlog Spreadsheet](deliverables/JIRA%20Exports.xlsx)**

- **JIRA Backlog in PDF: [Backlog PDF](deliverables/Jira%20Exports.pdf)**

- **Manual Scripted Tests: [Scripted Testing Spreadsheet](deliverables/Scripted%20Testing.xlsx)**


_If required, we can provide the access credentials to JIRA for better exploration._

# High-level description of the exploratory testing plan

We divided the high-level exploratory testing plan in a few steps, outlined below.

### Exploratory Analysis
The first and foremost step of exploring the functionalities of the system. Hence, each of the team members spent some time running the provided artifacts in their computers to get familiar with the provided system application.

When each team members were already introduced with the system, our plan for exploratory testing is as following:

1. Explore all functions and observe how the system behave.
2. Closely monitor the system in events of IO operations (e.g. user inputs, console output, logs, etc.)
3. Devise a list of operations supported by the ATM and list potential inputs and expected outputs.
4. Observe system behavior for "unhappy paths". For example: how the system handles incorrect inputs or maybe how it behaves in catastrophic events.
5. After each transaction, if a receipt is generated, check the receipt and system log.
6. Make sure all functions are well explored and tested.
7. In case a bug or defect found, list the bug in the designated JIRA backlog with the given template.

### Bug Report Template
```
Short description:

Function being tested:

Initial state of the system:

Steps to reproduce:

Version 1.0
----------------
Expected Outcome
Actual Outcome


Version 1.1
-----------------
Expected Outcome
Actual Outcome

Screenshot (If any)
```

For setting bug priority we used standard JIRA priority categories
```
Highest
High
Medium
Low
Lowest
```
### Test Scope/Functionalities under Test
- **Session**: Responsible for basic connection establishment, authorization, providing interface to the user to interact with the system.

- **Deposit**: Responsible for serving user requests to deposit money on different types of account.

- **Withdrawal**: Responsible for serving user requests to withdraw money from different types of account.

- **Balance Enquiry**: Checking customer's account balance.

- **Money Transfer**: Transferring money between customer's accounts.

- **Transaction, System Logs**: This functionality handles user's transaction request, logs, and receipt generation.

### Test Types
- Exploratory Testinng
- (Manual) Scripted Testing
- Regression Testing

# Comparison of exploratory and manual functional testing
In this section, we provide a comparative analysis of exploratory and manual functional testing and then briefly describe the effectiveness of both approaches for our system under test.

### Exploratory Testing:

- **Intuitive Approach:** Best used during the initial coding stages for quick feedback.
- **Speed Over Structure:** Faster due to its unstructured nature, but may lead to identifying the same bugs repeatedly.
- **Challenges in Documentation:** Difficulties in systematic documentation and recording of test results.
- **Unique Advantage:** Capable of uncovering unexpected and hidden bugs that might be overlooked in more structured
  testing processes.

### Manual Scripted Testing:

- **Comprehensive Approach:** Conducted after exploratory testing to ensure thorough bug detection.
- **Efficiency in Identifying Subtle Bugs:** Highly effective at finding subtle bugs missed during exploratory testing,
  thus enhancing bug tracking.
- **Advantage in Documentation:** Offers better capabilities in the systematic documentation and archiving of test
  results.
- **Prevents Redundancy:** More efficient in avoiding the redundant discovery of known bugs due to its structured
  nature.

### Effectiveness of Exploratory and Manual Testing for the SUT
While exploratory and manual functional testing both were effective and helped us find a lof of bugs from the SUT, we found exploratory testing more effective for the discussed ATM system is the provided 40 MFT cases were not simply enough to underlying severe bugs. However, it was really difficult to keep track of the bugs during ET as there were no predefined steps. It was more labor intensive and hard to reproduce and occassionally we could not reproduce a bug. 

Given the pros and cons for both approaches, we believe a balanced approach employing both technique would be really effective for testing.


# Notes and discussion of the peer reviews of defect reports
Peer development was typically supported  by peer reviewing, which made teamwork during testing possible. It also helped with possible bug identification, talking about features that needed to be tested, and making the process of reproducing bugs easier. We also dedicated several hours to deliberating between ourselves over the JIRA format and determining which Labels, Functions each bug ought to have.
We discovered a few problems during the exploratory testing phase and more errors during the manual scripted testing phase after hours of peer review and debate. If the issue has been fixed, update the status on JIRA; if not, leave it in To Do or In Progress mode. Accordingly, if a bug is shown as resolved in the latest version, it has been fixed and marked as **Done**; if it is marked as **To Do or In Progress**, it has persisted following the regression testing phase. Within the team, peer review was used to achieve each of these outcomes. Each team member has different approach to solve a particular problem. It helped us work in a team and solve the problem with ease.


# How the pair testing was managed and team work/effort was divided
For tackling the scripted testing, we distributed the bugs evenly to our team members. For example as there were 40 test cases to check, everyone in the team has 8 test cases to check. After checking the bug, we called up a meeting to discuss on the test cases. While checking the test cases, we were reproducing the steps properly and making sure that everything is working as expected. We also tested the bugs on Version 1.1 of the SUT. After getting bugs, we reported the bugs in JIRA, then we went through it. As each member is assigned 8 test cases, we completed this task easily.

For doing the Exploratory testing, we spent an hour to detect as much as bug as possible. We divided the teams into two. One team was Sayan and Afif while the other team was Abhi, Moshfiq and Sutirtha. After detecting the bugs, we came up in a meeting and compiled it into the list. The first time was specifically testing the functionality of Deposit, Session and Withdrawal while the other team was testing Balance and Transfer Functionality. The bugs which were found in the version 1.0, we tested those in the version 1.1. If the bug still persisted in version 1.1 we marked them as To Do or In Progress. In contrast, if the bug did not persist, we marked it as Done.


# Challenges Encountered, Solutions Implemented and Knowledge Acquired:

### Challenges Encountered
- **Bug Report Format:** During exploratory testing we discovered that multiple team members are reporting bugs in the backlog in different format which made it difficult to understand.
- **Undefined Test Scenarios:** The exploratory testing led to challenges in defining the scope and structure of test cases, complicating the testing process.
- **Documentation and Bug Management:** The unconventional methodology of exploratory testing posed hurdles in documenting and managing bugs efficiently.
- **Duplicate Bugs:** We also found cases where the same bug was reported by multiple members in the backlog which wasted a lot of time and we had to review the backlog to make sure each bug is unique.


### Solutions Implemented
- **Employing Global Bug Template:** As provided in an earlier section, we emplyed a generic template for reporting bugs so that it is easily understandable between the members.
- **Immediate Bug Reporting:** Adopted a strategy of reporting bugs as soon as they were discovered, bypassing the traditional steps for reproducing bugs. This approach is in line with the principles of exploratory testing, emphasizing immediate feedback and minimized duplicate bug reports.
- **Leverage Manual Testing's Comparative Advantage:** Recognized and utilized the strengths of manual testing for more accurate and efficient test execution, taking advantage of the nuanced insights that human testers can provide.

### Knowledge Acquired
- **Advantages of Manual Scripted Testing:** Acknowledged that manual scripted testing offers superior repeatability through the use of predefined test scripts. This enhances both the effectiveness and consistency of the testing approach by ensuring that tests can be reliably repeated to verify bug fixes or detect new issues under similar conditions. We now also believe that, a systematic plan of testing process (including bug template, test cases, etc.) provides more flexibility and saves a lot of time.

# Feedback of the Assignment
This assignment has helped us to know more about Scripted Testing and Exploratory Testing. As we coordinated highly with pairs, it has also helped us to actually work as a team and finish the assignment. We got to learn JIRA which was new to us. It also enhanced our practical skill and gave us fair knowledge on testing. The exploratory testing phase was particularly beneficial, as it allowed us to explore the software's functionalities in a more dynamic and inventive manner. On the other hand, the software that was chosen for this task was really suitable for beginners to learn testing. The peer review process was instrumental in ensuring the accuracy and uniformity of our bug reports. Overall, it was a good experience and we believe the experience will be helpful in the long run.